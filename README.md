# TIC-DSO â€” ReconstrucciÃ³n 3D Monocular en Android

> Proyecto de Tesis de IngenierÃ­a de Software  
> Autor: **Mateo SebastiÃ¡n Pilco PÃ©rez**  
> VersiÃ³n: `2.0` (Post-OptimizaciÃ³n DSO) â€” Diciembre 2025

---

## ğŸ“Œ DescripciÃ³n General

**TIC-DSO** es una aplicaciÃ³n Android que implementa un pipeline de **reconstrucciÃ³n 3D monocular en tiempo real**, integrando:

- **PixelFormer** (modelo de estimaciÃ³n de profundidad monocular, Agarwal et al., WACV 2023) corriendo en un servidor Flask remoto.
- **Grid-based Pixel Selector** adaptado de DSO (*Direct Sparse Odometry*, Engel et al., IEEE TPAMI 2018).
- VisualizaciÃ³n 3D interactiva estilo **Pangolin** implementada con Jetpack Compose Canvas.

La app permite reconstruir escenas 3D a partir de una Ãºnica cÃ¡mara (monocular), sin necesidad de sensores de profundidad dedicados (LiDAR, ToF, etc.).

---

## ğŸ—ï¸ Arquitectura del Sistema

El proyecto sigue **Clean Architecture** con el patrÃ³n **MVVM**, dividido en tres capas:

```
app/src/main/java/com/mateopilco/ticdso/
â”‚
â”œâ”€â”€ data/                          # Capa de Datos
â”‚   â”œâ”€â”€ network/                   # Retrofit + DTO
â”‚   â”œâ”€â”€ repository/                # ImplementaciÃ³n del repositorio
â”‚   â””â”€â”€ source/                    # Fuentes de imagen (CÃ¡mara / Dataset)
â”‚
â”œâ”€â”€ domain/                        # Capa de Negocio
â”‚   â”œâ”€â”€ model/                     # Modelos de dominio
â”‚   â”œâ”€â”€ repository/                # Interfaces del repositorio
â”‚   â””â”€â”€ source/                    # Interfaz Strategy (ImageSource)
â”‚
â”œâ”€â”€ presentation/                  # Capa de PresentaciÃ³n
â”‚   â”œâ”€â”€ ui/component/              # PointCloudViewer (renderizador 3D)
â”‚   â”œâ”€â”€ ui/screen/                 # HomeScreen
â”‚   â””â”€â”€ viewmodel/                 # MainViewModel + MainUiState
â”‚
â”œâ”€â”€ util/                          # Utilidades
â”‚   â”œâ”€â”€ PointsGenerator.kt         # âš¡âš¡ CORE â€” GeneraciÃ³n de nube de puntos
â”‚   â”œâ”€â”€ MathUtils.kt               # Ãlgebra 3D (matrices, poses)
â”‚   â”œâ”€â”€ BitmapUtils.kt             # Conversiones de imagen
â”‚   â””â”€â”€ Benchmarker.kt             # MediciÃ³n de rendimiento
â”‚
â””â”€â”€ MainActivity.kt
```

---

## ğŸ”„ Pipeline de ReconstrucciÃ³n 3D

```
1. CAPTURA (ImageSource)
   â”œâ”€ CameraImageSource  â†’  Frames YUV â†’ RGB vÃ­a CameraX, pose = Identidad
   â””â”€ DatasetImageSource â†’  Lee images/ + groundtruthSync.txt, pose = T_wc

2. ENVÃO (DepthRepository)
   â””â”€ POST http://{server}:5000/api/v1/predict  (imagen JPEG comprimida al 90%)

3. INFERENCIA (Servidor Flask â€” PixelFormer)
   â””â”€ Retorna mapa de profundidad normalizado

4. GENERACIÃ“N 3D (PointsGenerator)
   â”œâ”€ Grid-based Pixel Selector (bloques 32Ã—32, mÃ¡x 2 000 puntos/frame)
   â”œâ”€ Gradientes Sobel â†’ selecciÃ³n del pÃ­xel con mayor gradiente por bloque
   â””â”€ Back-projection a 3D con modelo Pinhole inverso

5. GESTIÃ“N (MainViewModel)
   â”œâ”€ Keyframe cada 10 frames
   â”œâ”€ Sliding Window (mÃ¡x 200 000 puntos globales, FIFO)
   â””â”€ Trayectoria de cÃ¡mara guardada por pose

6. RENDERIZADO (PointCloudViewer)
   â”œâ”€ Batch rendering con drawPoints()
   â”œâ”€ View Frustum Culling
   â”œâ”€ ProyecciÃ³n perspectiva 3D â†’ 2D
   â””â”€ Trayectoria + marcadores de keyframe estilo Pangolin
```

---

## âš¡ Optimizaciones Clave (v2.0)

### Grid-based Pixel Selector (basado en DSO `PixelSelector2.cpp`)

Reemplaza la iteraciÃ³n densa sobre toda la imagen por una selecciÃ³n por bloques, garantizando distribuciÃ³n espacial uniforme y control estricto de densidad.

| Constante | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| `BLOCK_SIZE` | 32 px | TamaÃ±o de cuadrÃ­cula (estÃ¡ndar DSO) |
| `MAX_POINTS_PER_FRAME` | 2 000 | LÃ­mite de puntos por frame |
| `GRADIENT_SQ_THRESHOLD` | 50 | Umbral de gradienteÂ² |
| `MIN_DEPTH` | 0.1 m | Profundidad mÃ­nima vÃ¡lida |
| `MAX_DEPTH` | 9.5 m | Profundidad mÃ¡xima vÃ¡lida |

### Resultados de Rendimiento

| MÃ©trica | Antes | DespuÃ©s | Mejora |
|---------|-------|---------|--------|
| Puntos/frame | 21 682 | ~2 000 | âœ… âˆ’90.8% |
| Tiempo proceso 3D | ~800 ms | ~120 ms | âœ… âˆ’85% |
| FPS de captura | 0.1 FPS | 1â€“2 FPS | âœ… +1 000% |
| Uso de CPU (render) | 80â€“90% | 25â€“30% | âœ… âˆ’66% |
| Uso de RAM | ~1.2 GB (crash) | ~450 MB (estable) | âœ… âˆ’62.5% |

---

## ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | TecnologÃ­a |
|-----------|-----------|
| Lenguaje | Kotlin |
| UI | Jetpack Compose |
| Estado | StateFlow + MVVM |
| Red | Retrofit 2 + OkHttp |
| CÃ¡mara | CameraX |
| Renderizado 3D | Compose Canvas |
| Backend | Python + Flask + PixelFormer |
| Arquitectura | Clean Architecture |

---

## ğŸš€ ConfiguraciÃ³n y Uso

### Requisitos previos

- Android Studio Hedgehog o superior
- Dispositivo/emulador con Android 8.0+ (API 26+)
- Servidor Flask con PixelFormer corriendo y accesible en la red local

### ConfiguraciÃ³n del servidor

En `RetrofitClient.kt`, configurar la IP del servidor:

```kotlin
private const val BASE_URL = "http://192.168.x.x:5000/"
```

Asegurarse de que `network_security_config.xml` permite trÃ¡fico cleartext a esa IP:

```xml
<domain-config cleartextTrafficPermitted="true">
    <domain>192.168.x.x</domain>
</domain-config>
```

### Modos de operaciÃ³n

- **Modo CÃ¡mara:** Captura frames en tiempo real desde la cÃ¡mara trasera del dispositivo. La pose es identidad (sin tracking de movimiento real aÃºn).
- **Modo Dataset:** Lee imÃ¡genes y poses ground-truth desde almacenamiento local, Ãºtil para evaluaciÃ³n reproducible.

---

## ğŸ§ª Casos de Prueba y Edge Cases

| Escenario | Comportamiento Esperado |
|-----------|------------------------|
| Servidor inaccesible | `ConnectionState.Error` â†’ UI muestra mensaje de error, sin crash |
| Mapa de profundidad nulo | Retorna lista vacÃ­a, continÃºa ejecuciÃ³n |
| Profundidad fuera de rango | PÃ­xel descartado silenciosamente |
| Sin calibraciÃ³n de dataset | Fallback: `fx=256, fy=254.4, cx=319.5, cy=239.5` |
| Memoria insuficiente | Sliding window actÃºa como FIFO; si persiste OOM, el job se cancela |

---

## ğŸ”® Deuda TÃ©cnica y Trabajo Futuro

### Pendiente inmediato
- [ ] Tests unitarios: `PointsGenerator.selectPixelsByGrid()`, `MathUtils`, sliding window en `MainViewModel`
- [ ] WebSocket para streaming continuo (reducir latencia de red)
- [ ] IntegraciÃ³n de ARCore para tracking de pose real 6DOF

### Mejoras a mediano plazo
- [ ] Migrar renderizado de Canvas a **OpenGL ES 3.0** (objetivo: 60 FPS con 1M puntos)
- [ ] Convertir PixelFormer a **TensorFlow Lite** para inferencia on-device (<500ms)
- [ ] Exportar nube de puntos a formato **PLY/PCD** y trayectoria en formato **TUM**
- [ ] Implementar Z-buffer para oclusiÃ³n correcta

---

## ğŸ“š Referencias

1. Engel, J., Koltun, V., & Cremers, D. (2018). *Direct Sparse Odometry.* IEEE TPAMI. DOI: [10.1109/TPAMI.2017.2658577](https://doi.org/10.1109/TPAMI.2017.2658577)
2. Agarwal et al. (2023). *Attention Attention Everywhere: Monocular Depth Prediction with Skip Attention (PixelFormer).* WACV 2023.
3. Lovegrove, S. et al. *Pangolin: Lightweight Portable Rapid Prototyping Visualisation Library.* [github.com/stevenlovegrove/Pangolin](https://github.com/stevenlovegrove/Pangolin)
4. CÃ³digo fuente de referencia DSO: `PixelSelector2.cpp`, `PangolinDSOViewer.cpp`, `settings.cpp`

---

## ğŸ“ ContribuciÃ³n a la Tesis

Este proyecto demuestra de forma prÃ¡ctica:

1. **AdaptaciÃ³n de algoritmos cientÃ­ficos** al entorno mÃ³vil Android (PixelSelector2 de DSO).
2. **Arquitectura Limpia en producciÃ³n** con MVVM, Strategy pattern, Repository pattern y StateFlow.
3. **OptimizaciÃ³n de recursos limitados**: ejecutar SLAM ligero en hardware mÃ³vil sin GPU de escritorio.
4. **VisualizaciÃ³n cientÃ­fica mÃ³vil**: replicaciÃ³n de Pangolin/DSO en Jetpack Compose.

---

*Documento generado como referencia tÃ©cnica para estudios futuros sobre reconstrucciÃ³n 3D monocular en dispositivos mÃ³viles.*